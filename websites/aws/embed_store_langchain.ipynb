{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62b7b184-d861-4cf5-b74b-9f298425626f",
   "metadata": {},
   "source": [
    "# Store posts to Vector Store FAISS\n",
    "\n",
    "Goal here is to ask questions related to content of the blog post material. \n",
    "To achieve this, we need to use Retrieval-Augmented-Generation (RAG) and create prompts that contain relevant context along with the query.\n",
    "\n",
    "In the previous [notebook](scrape_blogpost.ipynb) we extracted blog post content data from AWS Machine Learning blogs.\n",
    "\n",
    "In this notebook, we'll clean, split, encode and store the extracted blog post contents to a Vector Store ([FAISS](https://github.com/facebookresearch/faiss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "43cba441-ccef-44c1-b4a1-c59aba0fd697",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from pathlib import Path\n",
    "from typing import Dict, List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from bs4 import BeautifulSoup\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores.faiss import FAISS\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from pydantic import BaseModel\n",
    "from rich import print\n",
    "from torch import Tensor\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "import faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6f8425d6-6c5a-4d52-8875-edd874420496",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Root directory where all extracted blog post files are\n",
    "DATADIR = Path(\"../../data\")\n",
    "\n",
    "# Use rglob to recursively find all parquet files\n",
    "file_list = list(DATADIR.rglob(\"*.parquet\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8e2aaf02-1b59-4bff-b24c-1669b264cf16",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('data/aws/ml_blog_posts/rss/democratize-computer-vision-defect-detection-for-manufacturing-quality-using-no-code-machine-learning-with-amazon-sagemaker-canvas.parquet'),\n",
       " PosixPath('data/aws/ml_blog_posts/rss/retain-original-pdf-formatting-to-view-translated-documents-with-amazon-textract-amazon-translate-and-pdfbox.parquet'),\n",
       " PosixPath('data/aws/ml_blog_posts/rss/integrate-saas-platforms-with-amazon-sagemaker-to-enable-ml-powered-applications.parquet'),\n",
       " PosixPath('data/aws/ml_blog_posts/rss/recommend-and-dynamically-filter-items-based-on-user-context-in-amazon-personalize.parquet'),\n",
       " PosixPath('data/aws/ml_blog_posts/rss/use-proprietary-foundation-models-from-amazon-sagemaker-jumpstart-in-amazon-sagemaker-studio.parquet'),\n",
       " PosixPath('data/aws/ml_blog_posts/rss/use-the-aws-cdk-to-deploy-amazon-sagemaker-studio-lifecycle-configurations.parquet'),\n",
       " PosixPath('data/aws/ml_blog_posts/rss/deploy-a-serverless-ml-inference-endpoint-of-large-language-models-using-fastapi-aws-lambda-and-aws-cdk.parquet'),\n",
       " PosixPath('data/aws/ml_blog_posts/rss/effectively-solve-distributed-training-convergence-issues-with-amazon-sagemaker-hyperband-automatic-model-tuning.parquet'),\n",
       " PosixPath('data/aws/ml_blog_posts/rss/accelerate-time-to-business-insights-with-the-amazon-sagemaker-data-wrangler-direct-connection-to-snowflake.parquet'),\n",
       " PosixPath('data/aws/ml_blog_posts/rss/access-private-repos-using-the-remote-decorator-for-amazon-sagemaker-training-workloads.parquet'),\n",
       " PosixPath('data/aws/ml_blog_posts/rss/interactively-fine-tune-falcon-40b-and-other-llms-on-amazon-sagemaker-studio-notebooks-using-qlora.parquet'),\n",
       " PosixPath('data/aws/ml_blog_posts/rss/capture-public-health-insights-more-quickly-with-no-code-machine-learning-using-amazon-sagemaker-canvas.parquet'),\n",
       " PosixPath('data/aws/ml_blog_posts/rss/safe-image-generation-and-diffusion-models-with-amazon-ai-content-moderation-services.parquet'),\n",
       " PosixPath('data/aws/ml_blog_posts/rss/auto-labeling-module-for-deep-learning-based-advanced-driver-assistance-systems-on-aws.parquet'),\n",
       " PosixPath('data/aws/ml_blog_posts/rss/how-earth-com-and-provectus-implemented-their-mlops-infrastructure-with-amazon-sagemaker.parquet')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_list[0:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ef099f-65e6-4f5d-b551-21df8a640c86",
   "metadata": {},
   "source": [
    "## Extract Metadata from the stored parquet file\n",
    "\n",
    "Each parquet file is loaded to a pandas dataframe. Dataframe has the following columns\n",
    "- Title\n",
    "- Authors\n",
    "- Published Date\n",
    "- Tags\n",
    "- Content\n",
    "- URL\n",
    "- Image URLs (only when extracted via BeautifulSoup)\n",
    "\n",
    "We extract all columns, except Content, and prepare a *metadata* dictionary object.\n",
    "This *metadata* dictionary will be used when constructing Langchain's *document* object (`langchain.docstore.document.Document`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b3021d-fc42-4b0a-b0af-67e47923a13f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Encode and store processed text chunks to Vector Store\n",
    "\n",
    "Define text embedding model to encode the text chunks and store it to FAISS Vector Store\n",
    "\n",
    "~~We use **intfloat/e5-large-v2** model from huggingface as our embedding model.~~\n",
    "\n",
    "#### Save extracted doc embeddings to FAISS Index Locally\n",
    "\n",
    "- Here we make use of LangChains `FAISS.from_documents` helper function to ingest docs to FAISS with text embedding model.\n",
    "- If Index already exists on disk then skips creating a new index.\n",
    "- Here we do NOT use `TextSplitter` or `CharacterSplitter` as we have already split our documents with `create_langchain_documents` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "af547660-6cae-49f0-973e-8ddafb7ae650",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to clean text of html tags, URLs and special characters\n",
    "def clean_text(text):\n",
    "    # Remove HTML tags\n",
    "    text = BeautifulSoup(text, \"html.parser\").get_text()\n",
    "\n",
    "    # Remove URLs\n",
    "    # text = re.sub(r\"http[s]?://\\S+\", \"\", text)\n",
    "\n",
    "    # Lowercase the text\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove punctuation and special characters (optional)\n",
    "    # text = re.sub(r\"\\W\", \" \", text)\n",
    "\n",
    "    # Substitute multiple spaces with a single space\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "# Function to split content to paragraphs and then to passages\n",
    "def create_passages(\n",
    "    df: pd.DataFrame,\n",
    "    passage_window: int = 4,\n",
    ") -> List[str]:\n",
    "    # Extract blog post content as Corpus\n",
    "    corpus = clean_text(df.content[0])\n",
    "\n",
    "    # Split content as paragraphs and then into passages\n",
    "    paragraphs = []\n",
    "    for paragraph in corpus.replace(\"\\r\\n\", \"\\n\").split(\"\\n\\n\"):\n",
    "        if len(paragraph.strip()) > 0:\n",
    "            paragraphs.append(sent_tokenize(paragraph.strip()))\n",
    "\n",
    "    # We combine up to 3 sentences into a passage.\n",
    "    # You can choose smaller or larger values for window_size\n",
    "    # Smaller value: Context from other sentences might get lost\n",
    "    # Lager values: More context from the paragraph remains, but results are longer\n",
    "\n",
    "    window_size = passage_window\n",
    "    passages = []\n",
    "    for paragraph in paragraphs:\n",
    "        for start_idx in range(0, len(paragraph), window_size):\n",
    "            end_idx = min(start_idx + window_size, len(paragraph))\n",
    "            passages.append(\" \".join(paragraph[start_idx:end_idx]))\n",
    "\n",
    "    # print(\"Paragraphs: \", len(paragraphs))\n",
    "    # print(\"Sentences: \", sum([len(p) for p in paragraphs]))\n",
    "    # print(\"Passages: \", len(passages))\n",
    "    return passages\n",
    "\n",
    "\n",
    "# Function to ingest passages into a faiss index\n",
    "def ingest_passages_to_faiss(\n",
    "    docs: List[str], faiss_index: faiss.IndexFlatL2, index_filename: str\n",
    "):\n",
    "    for doc in tqdm(docs, total=len(docs), desc=\"Ingesting passages\"):\n",
    "        embeddings = encode_e5(doc)\n",
    "        faiss_index.add(embeddings)\n",
    "\n",
    "    print(f\"Saving index to {index_filename}\")\n",
    "    faiss.write_index(faiss_index, index_filename)\n",
    "\n",
    "\n",
    "def encode_e5(\n",
    "    corpus: str, model_id: str = \"intfloat/e5-base-v2\", normalize: bool = True\n",
    ") -> Tensor:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "    model = AutoModel.from_pretrained(model_id)\n",
    "\n",
    "    def average_pool(last_hidden_states: Tensor, attention_mask: Tensor) -> Tensor:\n",
    "        last_hidden = last_hidden_states.masked_fill(\n",
    "            ~attention_mask[..., None].bool(), 0.0\n",
    "        )\n",
    "        return last_hidden.sum(dim=1) / attention_mask.sum(dim=1)[..., None]\n",
    "\n",
    "    # tokenize input\n",
    "    tokenized_input = tokenizer(\n",
    "        corpus,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**tokenized_input)\n",
    "        embeddings = average_pool(\n",
    "            outputs.last_hidden_state, tokenized_input[\"attention_mask\"]\n",
    "        )\n",
    "\n",
    "    if normalize:\n",
    "        # (Optionally) normalize embeddings\n",
    "        embeddings = F.normalize(embeddings, p=2, dim=1)\n",
    "    # convert tensor to numpy array as faiss index accepts vectors as ndarrays\n",
    "    embeddings = embeddings.numpy()\n",
    "\n",
    "    return embeddings\n",
    "\n",
    "\n",
    "def get_embedding_dimensions(model_id: str) -> int:\n",
    "    model = AutoModel.from_pretrained(model_id)\n",
    "\n",
    "    # The embedding dimension is the size of the hidden states\n",
    "    embedding_dimension = model.config.hidden_size\n",
    "    return embedding_dimension\n",
    "\n",
    "\n",
    "def save_index(index, filename):\n",
    "    \"\"\"\n",
    "    Save the FAISS index to a file.\n",
    "    \"\"\"\n",
    "    faiss.write_index(index, filename)\n",
    "\n",
    "\n",
    "# Helper function to extract metadata from dataframe\n",
    "def extract_metadata(df) -> Dict:\n",
    "    data = {}\n",
    "    for column in df.columns:\n",
    "        for value in df[column]:\n",
    "            if str(column) != \"content\":\n",
    "                if isinstance(value, np.ndarray):\n",
    "                    data[column] = value.tolist()\n",
    "                else:\n",
    "                    data[column] = value\n",
    "\n",
    "    # convert values to lowercase, replace spaces with underscore\n",
    "    metadata = {}\n",
    "    for key, value in data.items():\n",
    "        new_key = key.lower().replace(\" \", \"_\")\n",
    "        metadata[new_key] = value\n",
    "    return metadata\n",
    "\n",
    "\n",
    "# Function to split content to paragraphs and then to passages\n",
    "def create_langchain_documents(\n",
    "    df: pd.DataFrame,\n",
    "    passage_window: int = 4,\n",
    ") -> List[Document]:\n",
    "    # Extract blog post content as Corpus\n",
    "    corpus = clean_text(df.content[0])\n",
    "\n",
    "    # Split content as paragraphs and then into passages\n",
    "    paragraphs = []\n",
    "    for paragraph in corpus.replace(\"\\r\\n\", \"\\n\").split(\"\\n\\n\"):\n",
    "        if len(paragraph.strip()) > 0:\n",
    "            paragraphs.append(sent_tokenize(paragraph.strip()))\n",
    "\n",
    "    # We combine up to 3 sentences into a passage.\n",
    "    # You can choose smaller or larger values for window_size\n",
    "    # Smaller value: Context from other sentences might get lost\n",
    "    # Lager values: More context from the paragraph remains, but results are longer\n",
    "\n",
    "    window_size = passage_window\n",
    "    passages = []\n",
    "    for paragraph in paragraphs:\n",
    "        for start_idx in range(0, len(paragraph), window_size):\n",
    "            end_idx = min(start_idx + window_size, len(paragraph))\n",
    "            passages.append(\" \".join(paragraph[start_idx:end_idx]))\n",
    "\n",
    "    # print(\"Paragraphs: \", len(paragraphs))\n",
    "    # print(\"Sentences: \", sum([len(p) for p in paragraphs]))\n",
    "    # print(\"Passages: \", len(passages))\n",
    "    docs = list()\n",
    "    num_passages = len(passages)\n",
    "\n",
    "    metadata = extract_metadata(df)\n",
    "    for i, passage in enumerate(passages):\n",
    "        # Create a copy of the metadata dictionary\n",
    "        metadata_copy = metadata.copy()\n",
    "        # Add current passage # as a new key-value pair\n",
    "        metadata_copy[\"passage\"] = f\"{i+1}/{num_passages}\"\n",
    "        docs.append(Document(page_content=clean_text(passage), metadata=metadata_copy))\n",
    "\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105d3c04-1148-4c2e-bb53-9381dae442d0",
   "metadata": {},
   "source": [
    "### Extract and Prepare data for encoding (embedding vector)\n",
    "\n",
    "\n",
    "To retrieve (search) relevant chunks of text for a give question, we perform a similarity search to find relevant chunks of text that are similar to the question.\n",
    "As our problem here is a \"asymmetric search\" problem, we'll need to choose a text embedding model that performs well for Retrieval tasks.\n",
    "\n",
    "We read the parquet file to a pandas dataframe and then extract all columns, except Content, as metadata.\n",
    "Read the \"Content\" of the blog_post as corpus and then split the content as paragraphs and then to passages comprising of 3 sentences.\n",
    "We then encode these passage chunks with an appropriate text embedding model and then store these embeddings into a vector store."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a49678",
   "metadata": {},
   "source": [
    "### Use CohereEmbeddings\n",
    "\n",
    "Create a `.env` file in the current directory with the following content\n",
    "\n",
    "```text\n",
    "COHERE_API_KEY=<YOUR_COHERE_API_EY>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7596a45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import CohereEmbeddings\n",
    "from dotenv import dotenv_values\n",
    "\n",
    "# Load the environment variables from the .env file\n",
    "env_vars = dotenv_values(\".env\")\n",
    "\n",
    "# Retrieve the API key from the loaded environment variables\n",
    "api_key = env_vars.get(\"COHERE_API_KEY\")\n",
    "cohere_embeddings = CohereEmbeddings(cohere_api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8d11b0af-b4e7-4eae-b5a7-6979792026a4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">No local index found, creating index from docs\n",
       "</pre>\n"
      ],
      "text/plain": [
       "No local index found, creating index from docs\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ingesting docs:   0%|          | 0/29 [00:00<?, ?it/s]/var/folders/kn/8wpz4sf966gfx5m_p4tynl300000gr/T/ipykernel_80285/1963419604.py:4: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  text = BeautifulSoup(text, \"html.parser\").get_text()\n",
      "Ingesting docs:   7%|▋         | 2/29 [00:01<00:21,  1.23it/s]/var/folders/kn/8wpz4sf966gfx5m_p4tynl300000gr/T/ipykernel_80285/1963419604.py:4: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  text = BeautifulSoup(text, \"html.parser\").get_text()\n",
      "Ingesting docs:  17%|█▋        | 5/29 [00:03<00:16,  1.47it/s]/var/folders/kn/8wpz4sf966gfx5m_p4tynl300000gr/T/ipykernel_80285/1963419604.py:4: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  text = BeautifulSoup(text, \"html.parser\").get_text()\n",
      "Ingesting docs:  21%|██        | 6/29 [00:04<00:16,  1.40it/s]/var/folders/kn/8wpz4sf966gfx5m_p4tynl300000gr/T/ipykernel_80285/1963419604.py:4: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  text = BeautifulSoup(text, \"html.parser\").get_text()\n",
      "Ingesting docs: 100%|██████████| 29/29 [00:20<00:00,  1.42it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Saving aws_ml_blog_posts locally\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Saving aws_ml_blog_posts locally\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use rglob to recursively find all parquet files\n",
    "file_list = list(DATADIR.rglob(\"*.parquet\"))\n",
    "INDEX_DIR = Path(\"./faiss\")\n",
    "INDEX_DIR.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# Define index name and index fullpath\n",
    "INDEX_NAME = \"aws_ml_blog_posts\"\n",
    "INDEX_FULLPATH = INDEX_DIR.joinpath(f\"{INDEX_NAME}.faiss\").absolute()\n",
    "\n",
    "# If index exists then load the local index\n",
    "if INDEX_FULLPATH.exists():\n",
    "    db = FAISS.load_local(\n",
    "        INDEX_DIR,\n",
    "        embeddings=cohere_embeddings,\n",
    "        index_name=INDEX_NAME,\n",
    "    )\n",
    "    print(f\"Loaded existing index: {INDEX_DIR}/{INDEX_NAME}\")\n",
    "else:\n",
    "    print(\"No local index found, creating index from docs\")\n",
    "    for parquet_file in tqdm(file_list, total=len(file_list), desc=\"Ingesting docs\"):\n",
    "        loaded_df = pd.read_parquet(parquet_file, engine=\"pyarrow\")\n",
    "        docs = create_langchain_documents(loaded_df)\n",
    "        db = FAISS.from_documents(docs, cohere_embeddings)\n",
    "\n",
    "    print(f\"Saving {INDEX_NAME} locally\")\n",
    "    FAISS.save_local(db, INDEX_DIR, INDEX_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac81fafb",
   "metadata": {},
   "source": [
    "### Evaluate results using similarity search\n",
    "\n",
    "We first encode the query vector and using the same embedding model then we use the `db.similarity_search_by_vector()` function to search for similar docs to our query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2298cb76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'you can delete the endpoints via the sagemaker console or from the studio notebook using the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">following commands: model_predictor.delete_model() model_predictor.delete_endpoint() conclusion in this post, we </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">gave an overview of the benefits of zero-shot learning and described how prompt engineering can improve the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">performance of instruction-tuned models. we also showed how to easily deploy an instruction-tuned flan t5 model </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">from jumpstart and provided examples to demonstrate how you can perform different nlp tasks using the deployed flan</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">t5 model endpoint in sagemaker. we encourage you to deploy a flan t5 model from jumpstart and create your own </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">prompts for nlp use cases. to learn more about jumpstart, check out the following: run text generation with bloom </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">and gpt models on amazon sagemaker jumpstart generate images from text with the stable diffusion model on amazon </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">sagemaker jumpstart run image segmentation with amazon sagemaker jumpstart run text classification with amazon </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">sagemaker jumpstart using tensorflow hub and hugging face models amazon sagemaker jumpstart models and algorithms </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">now available via api incremental training with amazon sagemaker jumpstart transfer learning for tensorflow object </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">detection models in amazon sagemaker transfer learning for tensorflow text classification models in amazon </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">sagemaker transfer learning for tensorflow image classification models in amazon sagemaker about the authors dr. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">xin huang is an applied scientist for amazon sagemaker jumpstart and amazon sagemaker built-in algorithms.'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'title'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Zero-shot prompting for the Flan-T5 foundation model in Amazon SageMaker JumpStart'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'tags'</span>: <span style=\"font-weight: bold\">[</span>\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'Amazon SageMaker'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'Amazon SageMaker JumpStart'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'Expert (400)'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'Generative AI'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'Technical How-to'</span>\n",
       "            <span style=\"font-weight: bold\">]</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'authors'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Vivek Gangasani'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Kyle Ulrich'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Xin Huang'</span><span style=\"font-weight: bold\">]</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'published_date'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'2023-04-03T10:37:07-08:00'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'https://aws.amazon.com/blogs/machine-learning/zero-shot-prompting-for-the-flan-t5-foundation-model-in-amazon-sagem</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">aker-jumpstart/'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'passage'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'39/42'</span>\n",
       "        <span style=\"font-weight: bold\">}</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'the following sections illustrate what each of these avenues look like and describe how to </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">access them. jumpstart foundation models developers can use the visual interface of the jumpstart foundation </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">models, accessed via the sagemaker console, to test instruction-tuned flan models without writing a single line of </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">code. this playground provides an input prompt textbox along with controls for various parameters used during </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">inference. this feature is currently in a gated preview, and you will see request access button instead of models </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">if you don’t have access.'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'title'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Zero-shot prompting for the Flan-T5 foundation model in Amazon SageMaker JumpStart'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'tags'</span>: <span style=\"font-weight: bold\">[</span>\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'Amazon SageMaker'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'Amazon SageMaker JumpStart'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'Expert (400)'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'Generative AI'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'Technical How-to'</span>\n",
       "            <span style=\"font-weight: bold\">]</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'authors'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Vivek Gangasani'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Kyle Ulrich'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Xin Huang'</span><span style=\"font-weight: bold\">]</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'published_date'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'2023-04-03T10:37:07-08:00'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'https://aws.amazon.com/blogs/machine-learning/zero-shot-prompting-for-the-flan-t5-foundation-model-in-amazon-sagem</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">aker-jumpstart/'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'passage'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'24/42'</span>\n",
       "        <span style=\"font-weight: bold\">}</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'as seen in the following screenshots, you can access foundation models in the navigation pane</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">of the sagemaker console. choose view model on the flan-t5 xl model card to access the user interface. you can use </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">this flexible user interface to try a demo of the model. sagemaker studio you can also access these models through </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the jumpstart landing page in studio.'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'title'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Zero-shot prompting for the Flan-T5 foundation model in Amazon SageMaker JumpStart'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'tags'</span>: <span style=\"font-weight: bold\">[</span>\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'Amazon SageMaker'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'Amazon SageMaker JumpStart'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'Expert (400)'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'Generative AI'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'Technical How-to'</span>\n",
       "            <span style=\"font-weight: bold\">]</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'authors'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Vivek Gangasani'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Kyle Ulrich'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Xin Huang'</span><span style=\"font-weight: bold\">]</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'published_date'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'2023-04-03T10:37:07-08:00'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'https://aws.amazon.com/blogs/machine-learning/zero-shot-prompting-for-the-flan-t5-foundation-model-in-amazon-sagem</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">aker-jumpstart/'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'passage'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'25/42'</span>\n",
       "        <span style=\"font-weight: bold\">}</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'deploy_image_uri = image_uris.retrieve( region=none, framework=none, # automatically inferred</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">from model_id image_scope=\"inference\", model_id=model_id, model_version=model_version, instance_type=instance_type,</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">) # retrieve the model uri. model_uri = model_uris.retrieve( model_id=model_id, model_version=model_version, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">model_scope=\"inference\" ) # create a sagemaker model object. model = model( image_uri=deploy_image_uri, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">model_data=model_uri, role=aws_role, predictor_cls=predictor, name=endpoint_name, ) # deploy the model. provide a </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">predictor_cls to use the sagemaker api for inference.'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'title'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Zero-shot prompting for the Flan-T5 foundation model in Amazon SageMaker JumpStart'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'tags'</span>: <span style=\"font-weight: bold\">[</span>\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'Amazon SageMaker'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'Amazon SageMaker JumpStart'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'Expert (400)'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'Generative AI'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'Technical How-to'</span>\n",
       "            <span style=\"font-weight: bold\">]</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'authors'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Vivek Gangasani'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Kyle Ulrich'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Xin Huang'</span><span style=\"font-weight: bold\">]</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'published_date'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'2023-04-03T10:37:07-08:00'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'https://aws.amazon.com/blogs/machine-learning/zero-shot-prompting-for-the-flan-t5-foundation-model-in-amazon-sagem</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">aker-jumpstart/'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'passage'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'28/42'</span>\n",
       "        <span style=\"font-weight: bold\">}</span>\n",
       "    <span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m'you can delete the endpoints via the sagemaker console or from the studio notebook using the \u001b[0m\n",
       "\u001b[32mfollowing commands: model_predictor.delete_model\u001b[0m\u001b[32m(\u001b[0m\u001b[32m)\u001b[0m\u001b[32m model_predictor.delete_endpoint\u001b[0m\u001b[32m(\u001b[0m\u001b[32m)\u001b[0m\u001b[32m conclusion in this post, we \u001b[0m\n",
       "\u001b[32mgave an overview of the benefits of zero-shot learning and described how prompt engineering can improve the \u001b[0m\n",
       "\u001b[32mperformance of instruction-tuned models. we also showed how to easily deploy an instruction-tuned flan t5 model \u001b[0m\n",
       "\u001b[32mfrom jumpstart and provided examples to demonstrate how you can perform different nlp tasks using the deployed flan\u001b[0m\n",
       "\u001b[32mt5 model endpoint in sagemaker. we encourage you to deploy a flan t5 model from jumpstart and create your own \u001b[0m\n",
       "\u001b[32mprompts for nlp use cases. to learn more about jumpstart, check out the following: run text generation with bloom \u001b[0m\n",
       "\u001b[32mand gpt models on amazon sagemaker jumpstart generate images from text with the stable diffusion model on amazon \u001b[0m\n",
       "\u001b[32msagemaker jumpstart run image segmentation with amazon sagemaker jumpstart run text classification with amazon \u001b[0m\n",
       "\u001b[32msagemaker jumpstart using tensorflow hub and hugging face models amazon sagemaker jumpstart models and algorithms \u001b[0m\n",
       "\u001b[32mnow available via api incremental training with amazon sagemaker jumpstart transfer learning for tensorflow object \u001b[0m\n",
       "\u001b[32mdetection models in amazon sagemaker transfer learning for tensorflow text classification models in amazon \u001b[0m\n",
       "\u001b[32msagemaker transfer learning for tensorflow image classification models in amazon sagemaker about the authors dr. \u001b[0m\n",
       "\u001b[32mxin huang is an applied scientist for amazon sagemaker jumpstart and amazon sagemaker built-in algorithms.'\u001b[0m,\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\n",
       "            \u001b[32m'title'\u001b[0m: \u001b[32m'Zero-shot prompting for the Flan-T5 foundation model in Amazon SageMaker JumpStart'\u001b[0m,\n",
       "            \u001b[32m'tags'\u001b[0m: \u001b[1m[\u001b[0m\n",
       "                \u001b[32m'Amazon SageMaker'\u001b[0m,\n",
       "                \u001b[32m'Amazon SageMaker JumpStart'\u001b[0m,\n",
       "                \u001b[32m'Expert \u001b[0m\u001b[32m(\u001b[0m\u001b[32m400\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m,\n",
       "                \u001b[32m'Generative AI'\u001b[0m,\n",
       "                \u001b[32m'Technical How-to'\u001b[0m\n",
       "            \u001b[1m]\u001b[0m,\n",
       "            \u001b[32m'authors'\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m'Vivek Gangasani'\u001b[0m, \u001b[32m'Kyle Ulrich'\u001b[0m, \u001b[32m'Xin Huang'\u001b[0m\u001b[1m]\u001b[0m,\n",
       "            \u001b[32m'published_date'\u001b[0m: \u001b[32m'2023-04-03T10:37:07-08:00'\u001b[0m,\n",
       "            \u001b[32m'source'\u001b[0m: \n",
       "\u001b[32m'https://aws.amazon.com/blogs/machine-learning/zero-shot-prompting-for-the-flan-t5-foundation-model-in-amazon-sagem\u001b[0m\n",
       "\u001b[32maker-jumpstart/'\u001b[0m,\n",
       "            \u001b[32m'passage'\u001b[0m: \u001b[32m'39/42'\u001b[0m\n",
       "        \u001b[1m}\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m'the following sections illustrate what each of these avenues look like and describe how to \u001b[0m\n",
       "\u001b[32maccess them. jumpstart foundation models developers can use the visual interface of the jumpstart foundation \u001b[0m\n",
       "\u001b[32mmodels, accessed via the sagemaker console, to test instruction-tuned flan models without writing a single line of \u001b[0m\n",
       "\u001b[32mcode. this playground provides an input prompt textbox along with controls for various parameters used during \u001b[0m\n",
       "\u001b[32minference. this feature is currently in a gated preview, and you will see request access button instead of models \u001b[0m\n",
       "\u001b[32mif you don’t have access.'\u001b[0m,\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\n",
       "            \u001b[32m'title'\u001b[0m: \u001b[32m'Zero-shot prompting for the Flan-T5 foundation model in Amazon SageMaker JumpStart'\u001b[0m,\n",
       "            \u001b[32m'tags'\u001b[0m: \u001b[1m[\u001b[0m\n",
       "                \u001b[32m'Amazon SageMaker'\u001b[0m,\n",
       "                \u001b[32m'Amazon SageMaker JumpStart'\u001b[0m,\n",
       "                \u001b[32m'Expert \u001b[0m\u001b[32m(\u001b[0m\u001b[32m400\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m,\n",
       "                \u001b[32m'Generative AI'\u001b[0m,\n",
       "                \u001b[32m'Technical How-to'\u001b[0m\n",
       "            \u001b[1m]\u001b[0m,\n",
       "            \u001b[32m'authors'\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m'Vivek Gangasani'\u001b[0m, \u001b[32m'Kyle Ulrich'\u001b[0m, \u001b[32m'Xin Huang'\u001b[0m\u001b[1m]\u001b[0m,\n",
       "            \u001b[32m'published_date'\u001b[0m: \u001b[32m'2023-04-03T10:37:07-08:00'\u001b[0m,\n",
       "            \u001b[32m'source'\u001b[0m: \n",
       "\u001b[32m'https://aws.amazon.com/blogs/machine-learning/zero-shot-prompting-for-the-flan-t5-foundation-model-in-amazon-sagem\u001b[0m\n",
       "\u001b[32maker-jumpstart/'\u001b[0m,\n",
       "            \u001b[32m'passage'\u001b[0m: \u001b[32m'24/42'\u001b[0m\n",
       "        \u001b[1m}\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m'as seen in the following screenshots, you can access foundation models in the navigation pane\u001b[0m\n",
       "\u001b[32mof the sagemaker console. choose view model on the flan-t5 xl model card to access the user interface. you can use \u001b[0m\n",
       "\u001b[32mthis flexible user interface to try a demo of the model. sagemaker studio you can also access these models through \u001b[0m\n",
       "\u001b[32mthe jumpstart landing page in studio.'\u001b[0m,\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\n",
       "            \u001b[32m'title'\u001b[0m: \u001b[32m'Zero-shot prompting for the Flan-T5 foundation model in Amazon SageMaker JumpStart'\u001b[0m,\n",
       "            \u001b[32m'tags'\u001b[0m: \u001b[1m[\u001b[0m\n",
       "                \u001b[32m'Amazon SageMaker'\u001b[0m,\n",
       "                \u001b[32m'Amazon SageMaker JumpStart'\u001b[0m,\n",
       "                \u001b[32m'Expert \u001b[0m\u001b[32m(\u001b[0m\u001b[32m400\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m,\n",
       "                \u001b[32m'Generative AI'\u001b[0m,\n",
       "                \u001b[32m'Technical How-to'\u001b[0m\n",
       "            \u001b[1m]\u001b[0m,\n",
       "            \u001b[32m'authors'\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m'Vivek Gangasani'\u001b[0m, \u001b[32m'Kyle Ulrich'\u001b[0m, \u001b[32m'Xin Huang'\u001b[0m\u001b[1m]\u001b[0m,\n",
       "            \u001b[32m'published_date'\u001b[0m: \u001b[32m'2023-04-03T10:37:07-08:00'\u001b[0m,\n",
       "            \u001b[32m'source'\u001b[0m: \n",
       "\u001b[32m'https://aws.amazon.com/blogs/machine-learning/zero-shot-prompting-for-the-flan-t5-foundation-model-in-amazon-sagem\u001b[0m\n",
       "\u001b[32maker-jumpstart/'\u001b[0m,\n",
       "            \u001b[32m'passage'\u001b[0m: \u001b[32m'25/42'\u001b[0m\n",
       "        \u001b[1m}\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m'deploy_image_uri = image_uris.retrieve\u001b[0m\u001b[32m(\u001b[0m\u001b[32m \u001b[0m\u001b[32mregion\u001b[0m\u001b[32m=\u001b[0m\u001b[32mnone\u001b[0m\u001b[32m, \u001b[0m\u001b[32mframework\u001b[0m\u001b[32m=\u001b[0m\u001b[32mnone\u001b[0m\u001b[32m, # automatically inferred\u001b[0m\n",
       "\u001b[32mfrom model_id \u001b[0m\u001b[32mimage_scope\u001b[0m\u001b[32m=\u001b[0m\u001b[32m\"inference\"\u001b[0m\u001b[32m, \u001b[0m\u001b[32mmodel_id\u001b[0m\u001b[32m=\u001b[0m\u001b[32mmodel_id\u001b[0m\u001b[32m, \u001b[0m\u001b[32mmodel_version\u001b[0m\u001b[32m=\u001b[0m\u001b[32mmodel_version\u001b[0m\u001b[32m, \u001b[0m\u001b[32minstance_type\u001b[0m\u001b[32m=\u001b[0m\u001b[32minstance_type\u001b[0m\u001b[32m,\u001b[0m\n",
       "\u001b[32m)\u001b[0m\u001b[32m # retrieve the model uri. model_uri = model_uris.retrieve\u001b[0m\u001b[32m(\u001b[0m\u001b[32m \u001b[0m\u001b[32mmodel_id\u001b[0m\u001b[32m=\u001b[0m\u001b[32mmodel_id\u001b[0m\u001b[32m, \u001b[0m\u001b[32mmodel_version\u001b[0m\u001b[32m=\u001b[0m\u001b[32mmodel_version\u001b[0m\u001b[32m, \u001b[0m\n",
       "\u001b[32mmodel_scope\u001b[0m\u001b[32m=\u001b[0m\u001b[32m\"inference\"\u001b[0m\u001b[32m \u001b[0m\u001b[32m)\u001b[0m\u001b[32m # create a sagemaker model object. model = model\u001b[0m\u001b[32m(\u001b[0m\u001b[32m \u001b[0m\u001b[32mimage_uri\u001b[0m\u001b[32m=\u001b[0m\u001b[32mdeploy_image_uri\u001b[0m\u001b[32m, \u001b[0m\n",
       "\u001b[32mmodel_data\u001b[0m\u001b[32m=\u001b[0m\u001b[32mmodel_uri\u001b[0m\u001b[32m, \u001b[0m\u001b[32mrole\u001b[0m\u001b[32m=\u001b[0m\u001b[32maws_role\u001b[0m\u001b[32m, \u001b[0m\u001b[32mpredictor_cls\u001b[0m\u001b[32m=\u001b[0m\u001b[32mpredictor\u001b[0m\u001b[32m, \u001b[0m\u001b[32mname\u001b[0m\u001b[32m=\u001b[0m\u001b[32mendpoint_name\u001b[0m\u001b[32m, \u001b[0m\u001b[32m)\u001b[0m\u001b[32m # deploy the model. provide a \u001b[0m\n",
       "\u001b[32mpredictor_cls to use the sagemaker api for inference.'\u001b[0m,\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\n",
       "            \u001b[32m'title'\u001b[0m: \u001b[32m'Zero-shot prompting for the Flan-T5 foundation model in Amazon SageMaker JumpStart'\u001b[0m,\n",
       "            \u001b[32m'tags'\u001b[0m: \u001b[1m[\u001b[0m\n",
       "                \u001b[32m'Amazon SageMaker'\u001b[0m,\n",
       "                \u001b[32m'Amazon SageMaker JumpStart'\u001b[0m,\n",
       "                \u001b[32m'Expert \u001b[0m\u001b[32m(\u001b[0m\u001b[32m400\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m,\n",
       "                \u001b[32m'Generative AI'\u001b[0m,\n",
       "                \u001b[32m'Technical How-to'\u001b[0m\n",
       "            \u001b[1m]\u001b[0m,\n",
       "            \u001b[32m'authors'\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m'Vivek Gangasani'\u001b[0m, \u001b[32m'Kyle Ulrich'\u001b[0m, \u001b[32m'Xin Huang'\u001b[0m\u001b[1m]\u001b[0m,\n",
       "            \u001b[32m'published_date'\u001b[0m: \u001b[32m'2023-04-03T10:37:07-08:00'\u001b[0m,\n",
       "            \u001b[32m'source'\u001b[0m: \n",
       "\u001b[32m'https://aws.amazon.com/blogs/machine-learning/zero-shot-prompting-for-the-flan-t5-foundation-model-in-amazon-sagem\u001b[0m\n",
       "\u001b[32maker-jumpstart/'\u001b[0m,\n",
       "            \u001b[32m'passage'\u001b[0m: \u001b[32m'28/42'\u001b[0m\n",
       "        \u001b[1m}\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "db = FAISS.load_local(\n",
    "    INDEX_DIR,\n",
    "    embeddings=cohere_embeddings,\n",
    "    index_name=INDEX_NAME,\n",
    ")\n",
    "\n",
    "query = \"What are some of the ways a model can be stored?\"\n",
    "\n",
    "# Embed the query and get the embeddings.\n",
    "encoded_query = cohere_embeddings.embed_query(query)\n",
    "\n",
    "results = db.similarity_search_by_vector(encoded_query, top_k=5)\n",
    "\n",
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
